# üìä Guide Complet du Syst√®me de Tracking OpenAI

## ‚ö†Ô∏è √âtat d'Impl√©mentation

**IMPORTANT** : Ce guide documente un syst√®me de tracking OpenAI qui est **partiellement impl√©ment√©** :
- ‚úÖ **Code d'int√©gration pr√©sent** : Le plugin r√©f√©rence les services dans `src/plugin.ts`
- ‚úÖ **Prompt syst√®me optimis√©** : R√©duit de 68% dans `src/character.ts`
- ‚úÖ **Routes API d√©finies** : Endpoints `/api/stats` et `/api/stats/reset` pr√©sents
- ‚ùå **Services manquants** : Les fichiers `openai-tracker.service.ts` et `openai-interceptor.service.ts` sont vides (0 octets)

**Le syst√®me ne fonctionnera pas tant que les services ne sont pas impl√©ment√©s.**

---

## üìã Vue d'ensemble

Le syst√®me de tracking OpenAI permet de surveiller et d'optimiser l'utilisation de l'API OpenAI dans l'agent Finance. Il comptabilise automatiquement les appels, les tokens consomm√©s, et estime les co√ªts en temps r√©el.

### Objectifs

- Suivre la consommation d'API OpenAI en temps r√©el
- Estimer les co√ªts par session et par mod√®le
- D√©tecter les patterns de surutilisation
- G√©n√©rer des recommandations d'optimisation automatiques
- Fournir une visibilit√© compl√®te via chat et API REST

---

## üéØ Fonctionnalit√©s Document√©es

### Tracking Automatique

- ‚úÖ Comptage des appels API (par mod√®le)
- ‚úÖ Suivi des tokens prompt et completion
- ‚úÖ Estimation des co√ªts en USD
- ‚úÖ D√©tection d'erreurs API
- ‚úÖ Statistiques de session avec timestamp

### Affichage Int√©gr√©

- ‚úÖ R√©sum√© compact dans chaque r√©ponse de l'agent
- ‚úÖ Commande d√©di√©e pour voir les stats d√©taill√©es (`SHOW_API_STATS`)
- ‚úÖ Endpoint API REST pour monitoring externe
- ‚úÖ Recommandations d'optimisation automatiques

### Alertes Automatiques

- ‚ö†Ô∏è Plus de 100 appels dans une session
- üí∞ Co√ªt d√©passant $1.00
- üîß Moyenne de tokens √©lev√©e (>2000 par appel)

---

## üöÄ Utilisation

### Dans le Chat avec l'Agent

#### Voir les Statistiques Compl√®tes

```
Montre-moi les stats API
```

ou

```
Combien de tokens j'ai consomm√© ?
```

L'agent affichera :

```
üìä **Statistiques d'utilisation OpenAI**

‚è±Ô∏è Dur√©e de la session : 15 minutes

**gpt-4o-mini**
‚îú‚îÄ Appels : 8
‚îú‚îÄ Tokens prompt : 3,245
‚îú‚îÄ Tokens completion : 1,892
‚îú‚îÄ Total tokens : 5,137
‚îú‚îÄ Erreurs : 0
‚îî‚îÄ Co√ªt estim√© : $0.001254

**text-embedding-3-small**
‚îú‚îÄ Appels : 12
‚îú‚îÄ Tokens prompt : 450
‚îú‚îÄ Tokens completion : 0
‚îú‚îÄ Total tokens : 450
‚îú‚îÄ Erreurs : 0
‚îî‚îÄ Co√ªt estim√© : $0.000009

**üìà Totaux de la session**
‚îú‚îÄ Appels totaux : 20
‚îú‚îÄ Tokens totaux : 5,587
‚îî‚îÄ Co√ªt total estim√© : $0.001263
```

#### R√©sum√© Automatique

Chaque r√©ponse de l'agent inclut automatiquement un r√©sum√© compact :

```
---
üí° **Session actuelle** : 8 appels | 5,137 tokens | ~$0.0013
```

### Via l'API REST

#### Obtenir les Statistiques

```bash
curl http://localhost:3000/api/stats
```

R√©ponse attendue :

```json
{
  "success": true,
  "timestamp": 1730311234567,
  "stats": {
    "gpt-4o-mini": {
      "totalCalls": 8,
      "totalPromptTokens": 3245,
      "totalCompletionTokens": 1892,
      "totalTokens": 5137,
      "estimatedCost": 0.001254,
      "lastCallTimestamp": 1730311234000,
      "errorCount": 0
    }
  },
  "threshold": null,
  "recommendations": [],
  "report": "..."
}
```

#### R√©initialiser les Statistiques

```bash
curl -X POST http://localhost:3000/api/stats/reset
```

---

## üîß Architecture Technique

### √âtat Actuel du Code

**Fichiers de Code Existant** :

1. **`src/plugin.ts`** (lignes 680-689, 853-862, 971-993, 1204-1253, 1282-1289)
   - Action `SHOW_API_STATS` d√©finie
   - Routes API `/api/stats` et `/api/stats/reset` configur√©es
   - Int√©gration des services dans les actions de surveillance
   - Services enregistr√©s dans la configuration du plugin

2. **`src/character.ts`** (lignes 50-59)
   - Prompt syst√®me optimis√© √† 380 tokens (r√©duction de 68%)
   - Configuration mod√®le : `gpt-4o-mini` et `text-embedding-3-small`

3. **`src/services/index.ts`**
   - Exports des services d√©finis mais non impl√©ment√©s

**Fichiers Manquants** (vides, 0 octets) :

1. **`src/services/openai-tracker.service.ts`** - **√Ä IMPL√âMENTER**
2. **`src/services/openai-interceptor.service.ts`** - **√Ä IMPL√âMENTER**

### Services √† Impl√©menter

#### 1. `OpenAITrackerService`

**Localisation** : `src/services/openai-tracker.service.ts`

**Responsabilit√©s** :
- Stockage des statistiques en m√©moire
- Calcul des co√ªts estim√©s bas√©s sur la tarification OpenAI
- G√©n√©ration de rapports format√©s
- V√©rification de seuils d'alerte
- R√©initialisation des statistiques

**M√©thodes Requises** :

```typescript
class OpenAITrackerService {
  trackCall(modelName: string, promptTokens: number, completionTokens: number, isError?: boolean): void
  getAllStats(): Record<string, ModelStats>
  generateReport(): string
  generateCompactSummary(): string | null
  checkThresholds(): { alert: boolean; message: string } | null
  resetStats(): void
}
```

**Interface de Statistiques par Mod√®le** :

```typescript
interface ModelStats {
  totalCalls: number
  totalPromptTokens: number
  totalCompletionTokens: number
  totalTokens: number
  estimatedCost: number
  lastCallTimestamp: number
  errorCount: number
}
```

#### 2. `OpenAIInterceptorService`

**Localisation** : `src/services/openai-interceptor.service.ts`

**Responsabilit√©s** :
- Interception des appels de g√©n√©ration OpenAI
- Estimation des tokens si non fournis dans la r√©ponse API
- Tracking automatique via le tracker
- G√©n√©ration de recommandations d'optimisation

**M√©thodes Requises** :

```typescript
class OpenAIInterceptorService {
  estimateTokens(text: string): number
  trackGeneration(modelName: string, prompt: string, response: string, actualTokens?: { prompt: number; completion: number }): void
  trackError(modelName: string, error: Error): void
  generateOptimizationRecommendations(): string[]
}
```

**Export Singleton** :

```typescript
export const openaiTracker = new OpenAITrackerService()
export const openaiInterceptor = new OpenAIInterceptorService()
```

### Action `SHOW_API_STATS`

**Localisation** : `src/plugin.ts` (lignes 946-1075)

**D√©clencheurs** :
- "montre-moi les stats API"
- "combien de tokens"
- "API usage"
- "consommation"

**Comportement** :
1. R√©cup√®re les statistiques du tracker
2. G√©n√®re un rapport complet
3. V√©rifie les seuils d'alerte
4. Ajoute des recommandations d'optimisation si disponibles

### Routes API

#### `GET /api/stats`
R√©cup√®re les statistiques compl√®tes en JSON avec :
- Statistiques par mod√®le
- Seuils d'alerte d√©tect√©s
- Recommandations d'optimisation
- Rapport format√©

#### `POST /api/stats/reset`
R√©initialise toutes les statistiques de session

---

## üí∞ Tarification OpenAI (Octobre 2024)

### Mod√®les de G√©n√©ration

| Mod√®le | Prompt ($/1M tokens) | Completion ($/1M tokens) |
|--------|---------------------|-------------------------|
| gpt-4o-mini | $0.15 | $0.60 |
| gpt-4o | $2.50 | $10.00 |
| gpt-4-turbo | $10.00 | $30.00 |

### Mod√®les d'Embedding

| Mod√®le | Prix ($/1M tokens) |
|--------|-------------------|
| text-embedding-3-small | $0.02 |
| text-embedding-3-large | $0.13 |

**Note** : Les tarifs doivent √™tre mis √† jour p√©riodiquement selon [openai.com/pricing](https://openai.com/pricing)

---

## üé® Optimisations R√©alis√©es

### 1. R√©duction du Prompt Syst√®me (~68% de tokens √©conomis√©s)

**Avant** (1,200 tokens) :
```
You are a specialized cryptocurrency portfolio surveillance agent operating in SURVEILLANCE-ONLY mode. Your primary role is to monitor Ethereum/EVM wallets and provide analysis and recommendations without executing any transactions.

CRITICAL RULES:
- NEVER execute transactions or sign transactions
- NEVER request or use private keys
- You operate in READ-ONLY mode using public addresses only
[... 29 lignes suppl√©mentaires ...]
```

**Apr√®s** (380 tokens) :
```
Agent de surveillance crypto READ-ONLY. Aucune transaction ex√©cut√©e.

R√àGLES:
- Mode lecture seule (adresses publiques uniquement)
- Actions: SURVEILLANCE_PORTEFEUILLE | PROPOSER_REBALANCING | SHOW_API_STATS
- Wallet auto-configur√© via EVM_PUBLIC_KEY

R√âPONSES:
- Pr√©cis avec chiffres/pourcentages
- Professionnel et informatif
- Rappeler que c'est conseil uniquement
```

**Impact** :
- **820 tokens √©conomis√©s par appel**
- Sur 100 appels : 82,000 tokens √©conomis√©s
- √âconomie estim√©e : ~$0.012 pour 100 appels avec gpt-4o-mini

**Code** : `src/character.ts` lignes 50-59

### 2. Mod√®le √âconomique par D√©faut

- `gpt-4o-mini` : ~85% moins cher que GPT-4
- `text-embedding-3-small` : mod√®le d'embedding √©conomique

**Code** : `src/character.ts` lignes 46-48

### 3. Int√©gration dans les Actions

Les statistiques sont automatiquement ajout√©es aux r√©ponses des actions :
- `SURVEILLANCE_PORTEFEUILLE` (lignes 680-689)
- `PROPOSER_REBALANCING` (lignes 853-862)

**Code** : `src/plugin.ts`

---

## üìà M√©triques de Performance

### Sc√©nario Typique : Consultation de Portfolio

**Sans Optimisations** :
- Appels par consultation : ~4-6 (d√©cision d'action + g√©n√©ration de r√©ponse + embeddings)
- Tokens moyens par appel : ~1,800
- Co√ªt par consultation : ~$0.0025

**Avec Optimisations** :
- Appels par consultation : ~4-6 (identique)
- Tokens moyens par appel : ~900
- Co√ªt par consultation : ~$0.0012

**√âconomie** : **~52% de r√©duction de co√ªt**

### Projections de Co√ªts

#### Sur 1,000 Interactions

| M√©trique | Avant | Apr√®s | √âconomie |
|----------|-------|-------|----------|
| Tokens totaux | 1,800,000 | 900,000 | 900,000 |
| Co√ªt estim√© | $2.50 | $1.20 | **$1.30** |

#### Sur 10,000 Interactions

| M√©trique | Avant | Apr√®s | √âconomie |
|----------|-------|-------|----------|
| Tokens totaux | 18,000,000 | 9,000,000 | 9,000,000 |
| Co√ªt estim√© | $25.00 | $12.00 | **$13.00** |

---

## üéØ Strat√©gies d'Optimisation Futures

### 1. R√©duction des Appels Redondants

#### Cache des R√©ponses Similaires

Pour √©viter de r√©p√©ter les m√™mes appels OpenAI pour des requ√™tes similaires :

```typescript
// Exemple de cache simple (√† impl√©menter)
const responseCache = new Map<string, { response: string; timestamp: number }>()
const CACHE_TTL = 5 * 60 * 1000 // 5 minutes

function getCachedResponse(prompt: string): string | null {
  const cached = responseCache.get(prompt)
  if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
    return cached.response
  }
  return null
}
```

#### Batch des Requ√™tes Similaires

Grouper plusieurs requ√™tes similaires en une seule si possible.

### 2. Optimisation des Prompts

#### Prompts Plus Courts
- Utiliser des instructions concises
- √âviter la r√©p√©tition d'informations
- Utiliser des abr√©viations quand appropri√©

#### Contexte Minimal
- N'inclure que le contexte n√©cessaire
- √âviter de r√©p√©ter tout l'historique √† chaque appel
- Utiliser des r√©f√©rences plut√¥t que du contenu complet

### 3. S√©lection du Mod√®le Appropri√©

#### GPT-4o-mini pour la Majorit√© des Cas
Le mod√®le `gpt-4o-mini` est d√©j√† configur√© par d√©faut car il offre :
- ‚úÖ Co√ªt r√©duit (~85% moins cher que GPT-4)
- ‚úÖ Latence r√©duite
- ‚úÖ Performance suffisante pour la plupart des t√¢ches

#### GPT-4 pour les T√¢ches Complexes Uniquement
R√©server GPT-4 pour :
- Analyses complexes de portefeuille
- Contextes tr√®s longs
- Raisonnements approfondis

### 4. R√©duction du Contexte

#### Limiter la Fen√™tre de M√©moire

```typescript
// Dans character.ts
settings: {
  maxMemories: 100, // Limiter √† 100 au lieu de 1000+
  memoryDecay: 0.95, // Oublier progressivement les anciens messages
}
```

#### Filtrer les M√©moires Pertinentes
N'inclure que les m√©moires directement pertinentes au contexte actuel.

### 5. Configuration du Temperature

```typescript
// Dans character.ts ou plugin.ts
settings: {
  temperature: 0.7, // Par d√©faut
  // Pour des r√©ponses plus d√©terministes et √©conomes :
  temperature: 0.5, // R√©duit la variabilit√© et peut r√©duire les tokens
}
```

### 6. Streaming des R√©ponses

Le streaming permet de commencer √† afficher la r√©ponse avant qu'elle ne soit compl√®te, r√©duisant la perception de latence.

---

## üîß Configuration Avanc√©e

### Configuration Recommand√©e

#### Pour Usage G√©n√©ral (√âconomique)

```typescript
settings: {
  model: 'gpt-4o-mini',
  embeddingModel: 'text-embedding-3-small',
  temperature: 0.7,
  maxMemories: 100,
  memoryDecay: 0.95,
}
```

#### Pour Performance Maximale

```typescript
settings: {
  model: 'gpt-4o-mini',
  embeddingModel: 'text-embedding-3-small',
  temperature: 0.5,
  maxMemories: 50,
  memoryDecay: 0.9,
  maxTokens: 2000, // Limiter la longueur des r√©ponses
}
```

### Modifier les Seuils d'Alerte

Une fois les services impl√©ment√©s, modifiez les seuils dans `src/services/openai-tracker.service.ts` :

```typescript
// Seuils d'alerte configurables
if (totalCalls > 100) {  // Modifier le seuil ici
  return {
    alert: true,
    message: `‚ö†Ô∏è Alerte : ${totalCalls} appels API...`
  }
}
```

### Ajouter des Tarifs Personnalis√©s

Si vous utilisez des mod√®les diff√©rents, ajoutez-les dans `OPENAI_PRICING` :

```typescript
const OPENAI_PRICING: Record<string, { prompt: number; completion: number }> = {
  'votre-modele': {
    prompt: 0.001 / 1000,     // Prix par token
    completion: 0.002 / 1000,
  },
  // ... autres mod√®les
}
```

### D√©sactiver le R√©sum√© Automatique

Commentez l'ajout du r√©sum√© dans les actions (`src/plugin.ts` lignes ~681, ~855) :

```typescript
// D√©sactiver le r√©sum√© compact
/*
try {
  const { openaiTracker } = await import('./services/openai-tracker.service')
  const compactSummary = openaiTracker.generateCompactSummary()
  if (compactSummary) {
    portfolioText += compactSummary
  }
} catch (err) {
  logger.warn('Could not fetch API stats:', err)
}
*/
```

---

## üß™ Tests et Validation

### Tester le Tracking (Une Fois Impl√©ment√©)

1. D√©marrer l'agent :
```bash
cd finance-agent
bun run dev
```

2. Faire quelques requ√™tes dans le chat

3. Consulter les statistiques :
```
Montre-moi les stats API
```

4. V√©rifier via l'API :
```bash
curl http://localhost:3000/api/stats | jq
```

### R√©initialiser pour un Nouveau Test

Via l'API :
```bash
curl -X POST http://localhost:3000/api/stats/reset
```

---

## üö® Troubleshooting

### Les Stats N'Apparaissent Pas

**V√©rifications** :
1. Les services sont-ils impl√©ment√©s ? ‚Üí V√©rifier que les fichiers de services ne sont pas vides
2. Le service est bien charg√© ? ‚Üí V√©rifier les logs au d√©marrage
3. Les imports fonctionnent ? ‚Üí V√©rifier `src/services/index.ts`
4. L'action est disponible ? ‚Üí Dire "SHOW_API_STATS" dans le chat

### Les Estimations de Co√ªt Semblent Incorrectes

**Causes Possibles** :
1. Tarifs OpenAI obsol√®tes ‚Üí V√©rifier sur https://openai.com/pricing
2. Estimation de tokens impr√©cise ‚Üí Les tokens r√©els viennent de l'API OpenAI si disponibles
3. Mod√®le non reconnu ‚Üí Ajouter le mod√®le dans `OPENAI_PRICING`

### Les Appels Ne Sont Pas Track√©s

**Solution** :
Le tracking automatique repose sur l'interception. Si vous utilisez directement l'API OpenAI sans passer par le runtime ElizaOS, le tracking ne fonctionnera pas.

### Trop d'Appels D√©tect√©s

1. V√©rifier s'il y a des boucles dans le code
2. S'assurer que le cache fonctionne si impl√©ment√©
3. V√©rifier les prompts syst√®me pour √©viter les appels redondants

### Trop de Tokens

1. R√©duire `maxMemories` dans les settings
2. Optimiser les prompts syst√®me pour √™tre plus concis
3. Limiter `maxTokens` dans les param√®tres de g√©n√©ration

### Latence √âlev√©e

1. Utiliser `gpt-4o-mini` au lieu de GPT-4
2. Activer le streaming si disponible
3. R√©duire la taille du contexte

---

## üí° Bonnes Pratiques

1. **R√©utiliser les R√©ponses** : Si une question similaire a d√©j√† √©t√© pos√©e, r√©utiliser la r√©ponse
2. **Prompt Engineering** : Investir du temps √† optimiser les prompts syst√®me
3. **Limiter le Contexte** : Ne pas inclure tout l'historique si ce n'est pas n√©cessaire
4. **Choisir le Bon Mod√®le** : Utiliser gpt-4o-mini par d√©faut, GPT-4 seulement si n√©cessaire
5. **Monitorer les Co√ªts** : V√©rifier r√©guli√®rement les m√©triques affich√©es

---

## üéØ Objectifs de R√©duction

Objectifs recommand√©s :
- **R√©duction de 30-50%** des tokens en optimisant les prompts
- **R√©duction de 20-40%** des appels en utilisant un cache
- **R√©duction de 85%** des co√ªts en utilisant gpt-4o-mini au lieu de GPT-4

---

## üéì Le√ßons Apprises

### 1. Le Prompt Syst√®me est Critique
- **Impact majeur** sur la consommation de tokens
- Chaque token du prompt syst√®me est envoy√© √† **chaque appel**
- R√©duction de 820 tokens = √©conomie de ~68% par appel

### 2. La Visibilit√© Change Tout
- Sans m√©triques, impossible d'optimiser
- Le tracking permet d'identifier les probl√®mes
- Les recommandations automatiques guident les am√©liorations

### 3. L'Optimisation est It√©rative
- Mesurer d'abord
- Optimiser ensuite
- Valider l'impact
- R√©p√©ter

---

## üîú Prochaines √âtapes

### √Ä Impl√©menter (Priorit√© Haute)

1. **Services de Tracking** :
   - [ ] Impl√©menter `OpenAITrackerService` avec toutes les m√©thodes document√©es
   - [ ] Impl√©menter `OpenAIInterceptorService` avec interception des appels
   - [ ] Int√©grer l'interception dans le runtime ElizaOS

2. **Tests** :
   - [ ] Tests unitaires pour les services
   - [ ] Tests d'int√©gration pour les routes API
   - [ ] Validation des estimations de co√ªts

### Am√©liorations Futures (Priorit√© Moyenne)

- [ ] Persistence des statistiques dans PostgreSQL
- [ ] Dashboard web d√©di√© avec graphiques
- [ ] Alertes par email/Discord quand seuils d√©pass√©s
- [ ] Tracking des embeddings s√©par√©ment
- [ ] Export CSV des statistiques
- [ ] Comparaison de co√ªts entre sessions
- [ ] Budgets quotidiens/mensuels configurables

### Optimisations Avanc√©es (Priorit√© Basse)

- [ ] Cache des r√©ponses similaires
- [ ] Batching des requ√™tes
- [ ] Comparaison automatique des mod√®les
- [ ] A/B testing de prompts
- [ ] ML pour pr√©dire la consommation future

---

## üìö Ressources

- [Documentation OpenAI Pricing](https://openai.com/pricing)
- [ElizaOS Documentation](https://github.com/elizaos/eliza)
- [Guide d'optimisation des prompts](https://platform.openai.com/docs/guides/prompt-engineering)

---

## üìù Notes de Maintenance

**Date de cr√©ation** : D√©cembre 2024  
**Version** : 1.0.0  
**√âtat** : Services document√©s mais non impl√©ment√©s  
**Prochaine r√©vision** : Apr√®s impl√©mentation des services

**Tarifs OpenAI** : √Ä mettre √† jour p√©riodiquement selon https://openai.com/pricing

---

## üìÅ Fichiers du Projet

### Code Existant

```
finance-agent/
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ character.ts                    [MODIFI√â] Prompt syst√®me optimis√© (380 tokens)
‚îÇ  ‚îú‚îÄ plugin.ts                       [MODIFI√â] 
‚îÇ  ‚îÇ  ‚îú‚îÄ Action SHOW_API_STATS       (lignes 946-1075)
‚îÇ  ‚îÇ  ‚îú‚îÄ Routes /api/stats           (lignes 1204-1253)
‚îÇ  ‚îÇ  ‚îú‚îÄ Services enregistr√©s        (lignes 1282-1289)
‚îÇ  ‚îÇ  ‚îî‚îÄ Stats auto-affich√©es        (lignes 680-689, 853-862)
‚îÇ  ‚îî‚îÄ services/
‚îÇ     ‚îú‚îÄ index.ts                     [EXISTANT] Exports d√©finis
‚îÇ     ‚îú‚îÄ openai-tracker.service.ts   [VIDE - √Ä IMPL√âMENTER]
‚îÇ     ‚îî‚îÄ openai-interceptor.service.ts [VIDE - √Ä IMPL√âMENTER]
```

### Documentation

```
finance-agent/
‚îî‚îÄ docs/
   ‚îî‚îÄ OPENAI-TRACKING-GUIDE.md       [CE FICHIER - Consolid√©]
```

