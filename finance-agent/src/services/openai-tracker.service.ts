/**
 * Service de tracking des appels OpenAI
 * Comptabilise les appels, tokens consomm√©s et estime les co√ªts en temps r√©el
 */

/**
 * Tarification OpenAI (mise √† jour Octobre 2024)
 * Prix par million de tokens
 */
const OPENAI_PRICING: Record<string, { prompt: number; completion: number }> = {
  'gpt-4o-mini': {
    prompt: 0.15 / 1_000_000,      // $0.15 par 1M tokens
    completion: 0.60 / 1_000_000,  // $0.60 par 1M tokens
  },
  'gpt-4o': {
    prompt: 2.50 / 1_000_000,       // $2.50 par 1M tokens
    completion: 10.00 / 1_000_000,  // $10.00 par 1M tokens
  },
  'gpt-4-turbo': {
    prompt: 10.00 / 1_000_000,      // $10.00 par 1M tokens
    completion: 30.00 / 1_000_000,  // $30.00 par 1M tokens
  },
  // Mod√®les gpt-5 (utilis√©s par ElizaOS pour certaines t√¢ches)
  'gpt-5-nano-2025-08-07': {
    prompt: 0.05 / 1_000_000,      // Estimation: tr√®s l√©ger, moins cher que mini
    completion: 0.20 / 1_000_000,  // Estimation: tr√®s l√©ger
  },
  'gpt-5-mini-2025-08-07': {
    prompt: 0.10 / 1_000_000,      // Estimation: l√©ger, similaire √† gpt-4o-mini
    completion: 0.40 / 1_000_000,  // Estimation: l√©ger
  },
  'gpt-5-mini': {
    prompt: 0.10 / 1_000_000,      // Alias sans date
    completion: 0.40 / 1_000_000,
  },
  'gpt-5-nano': {
    prompt: 0.05 / 1_000_000,      // Alias sans date
    completion: 0.20 / 1_000_000,
  },
  'text-embedding-3-small': {
    prompt: 0.02 / 1_000_000,       // $0.02 par 1M tokens (embedding uniquement)
    completion: 0,                   // Pas de completion pour les embeddings
  },
  'text-embedding-3-large': {
    prompt: 0.13 / 1_000_000,       // $0.13 par 1M tokens
    completion: 0,
  },
};

/**
 * Interface pour les statistiques d'un mod√®le
 */
export interface ModelStats {
  totalCalls: number;
  totalPromptTokens: number;
  totalCompletionTokens: number;
  totalTokens: number;
  estimatedCost: number;
  lastCallTimestamp: number;
  errorCount: number;
}

/**
 * Seuils d'alerte configurables
 */
const ALERT_THRESHOLDS = {
  MAX_CALLS: 100,           // Alerte si plus de 100 appels
  MAX_COST_USD: 1.0,       // Alerte si co√ªt d√©passe $1.00
  MAX_AVG_TOKENS: 2000,    // Alerte si moyenne > 2000 tokens par appel
};

/**
 * Service de tracking des appels OpenAI
 * Stocke les statistiques en m√©moire et calcule les co√ªts estim√©s
 */
export class OpenAITrackerService {
  private stats: Map<string, ModelStats> = new Map();
  private sessionStartTime: number = Date.now();

  /**
   * Enregistre un appel API OpenAI
   * @param modelName Nom du mod√®le utilis√©
   * @param promptTokens Nombre de tokens du prompt
   * @param completionTokens Nombre de tokens de la completion
   * @param isError Si l'appel a g√©n√©r√© une erreur
   */
  trackCall(
    modelName: string,
    promptTokens: number,
    completionTokens: number,
    isError: boolean = false
  ): void {
    const currentStats = this.stats.get(modelName) || {
      totalCalls: 0,
      totalPromptTokens: 0,
      totalCompletionTokens: 0,
      totalTokens: 0,
      estimatedCost: 0,
      lastCallTimestamp: 0,
      errorCount: 0,
    };

    // Mettre √† jour les statistiques
    currentStats.totalCalls += 1;
    currentStats.totalPromptTokens += promptTokens;
    currentStats.totalCompletionTokens += completionTokens;
    currentStats.totalTokens += promptTokens + completionTokens;
    currentStats.lastCallTimestamp = Date.now();

    if (isError) {
      currentStats.errorCount += 1;
    }

    // Calculer le co√ªt estim√©
    const pricing = OPENAI_PRICING[modelName] || OPENAI_PRICING['gpt-4o-mini'];
    const promptCost = promptTokens * pricing.prompt;
    const completionCost = completionTokens * pricing.completion;
    currentStats.estimatedCost += promptCost + completionCost;

    // Sauvegarder les statistiques mises √† jour
    this.stats.set(modelName, currentStats);
  }

  /**
   * R√©cup√®re toutes les statistiques par mod√®le
   * @returns Objet avec les statistiques par mod√®le
   */
  getAllStats(): Record<string, ModelStats> {
    const result: Record<string, ModelStats> = {};
    for (const [modelName, stats] of this.stats.entries()) {
      result[modelName] = { ...stats };
    }
    return result;
  }

  /**
   * G√©n√®re un rapport complet format√© pour l'affichage
   * @returns Rapport format√© en texte
   */
  generateReport(): string {
    const stats = this.getAllStats();
    const modelNames = Object.keys(stats);

    if (modelNames.length === 0) {
      return 'üìä **Statistiques d\'utilisation OpenAI**\n\nAucun appel API enregistr√© pour cette session.';
    }

    // Calculer la dur√©e de la session
    const sessionDuration = Date.now() - this.sessionStartTime;
    const sessionMinutes = Math.floor(sessionDuration / 60000);
    const sessionSeconds = Math.floor((sessionDuration % 60000) / 1000);

    let report = 'üìä **Statistiques d\'utilisation OpenAI**\n\n';
    report += `‚è±Ô∏è Dur√©e de la session : ${sessionMinutes} minute${sessionMinutes > 1 ? 's' : ''} ${sessionSeconds > 0 ? `${sessionSeconds} seconde${sessionSeconds > 1 ? 's' : ''}` : ''}\n\n`;

    // Statistiques par mod√®le
    for (const modelName of modelNames) {
      const modelStats = stats[modelName];
      report += `**${modelName}**\n`;
      report += `‚îú‚îÄ Appels : ${modelStats.totalCalls}\n`;
      report += `‚îú‚îÄ Tokens prompt : ${modelStats.totalPromptTokens.toLocaleString('fr-FR')}\n`;
      report += `‚îú‚îÄ Tokens completion : ${modelStats.totalCompletionTokens.toLocaleString('fr-FR')}\n`;
      report += `‚îú‚îÄ Total tokens : ${modelStats.totalTokens.toLocaleString('fr-FR')}\n`;
      report += `‚îú‚îÄ Erreurs : ${modelStats.errorCount}\n`;
      report += `‚îî‚îÄ Co√ªt estim√© : $${modelStats.estimatedCost.toFixed(6)}\n\n`;
    }

    // Totaux de la session
    const totals = this.calculateTotals();
    report += '**üìà Totaux de la session**\n';
    report += `‚îú‚îÄ Appels totaux : ${totals.totalCalls}\n`;
    report += `‚îú‚îÄ Tokens totaux : ${totals.totalTokens.toLocaleString('fr-FR')}\n`;
    report += `‚îî‚îÄ Co√ªt total estim√© : $${totals.totalCost.toFixed(6)}\n`;

    return report;
  }

  /**
   * G√©n√®re un r√©sum√© compact pour affichage dans les r√©ponses
   * @returns R√©sum√© compact ou null si aucun appel
   */
  generateCompactSummary(): string | null {
    const totals = this.calculateTotals();

    if (totals.totalCalls === 0) {
      return null;
    }

    const costStr = totals.totalCost < 0.0001 
      ? `< $0.0001` 
      : `~$${totals.totalCost.toFixed(4)}`;

    return `\n---\nüí° **Session actuelle** : ${totals.totalCalls} appels | ${totals.totalTokens.toLocaleString('fr-FR')} tokens | ${costStr}`;
  }

  /**
   * V√©rifie si des seuils d'alerte sont d√©pass√©s
   * @returns Objet avec l'alerte et le message, ou null si aucun seuil d√©pass√©
   */
  checkThresholds(): { alert: boolean; message: string } | null {
    const totals = this.calculateTotals();
    const alerts: string[] = [];

    // V√©rifier le nombre d'appels
    if (totals.totalCalls > ALERT_THRESHOLDS.MAX_CALLS) {
      alerts.push(`‚ö†Ô∏è Alerte : ${totals.totalCalls} appels API d√©tect√©s dans cette session (seuil: ${ALERT_THRESHOLDS.MAX_CALLS})`);
    }

    // V√©rifier le co√ªt total
    if (totals.totalCost > ALERT_THRESHOLDS.MAX_COST_USD) {
      alerts.push(`üí∞ Alerte : Co√ªt total de $${totals.totalCost.toFixed(4)} d√©passe le seuil de $${ALERT_THRESHOLDS.MAX_COST_USD}`);
    }

    // V√©rifier la moyenne de tokens par appel
    if (totals.totalCalls > 0) {
      const avgTokens = totals.totalTokens / totals.totalCalls;
      if (avgTokens > ALERT_THRESHOLDS.MAX_AVG_TOKENS) {
        alerts.push(`üîß Alerte : Moyenne de ${Math.round(avgTokens)} tokens par appel (seuil: ${ALERT_THRESHOLDS.MAX_AVG_TOKENS})`);
      }
    }

    // V√©rifier les erreurs par mod√®le
    const stats = this.getAllStats();
    for (const [modelName, modelStats] of Object.entries(stats)) {
      if (modelStats.errorCount > 5) {
        alerts.push(`‚ö†Ô∏è ${modelStats.errorCount} erreurs d√©tect√©es avec ${modelName}. V√©rifiez votre cl√© API et les limites de rate limit.`);
      }
    }

    if (alerts.length === 0) {
      return null;
    }

    return {
      alert: true,
      message: alerts.join('\n\n'),
    };
  }

  /**
   * R√©initialise toutes les statistiques
   */
  resetStats(): void {
    this.stats.clear();
    this.sessionStartTime = Date.now();
  }

  /**
   * Calcule les totaux de la session
   * @returns Totaux agr√©g√©s
   */
  private calculateTotals(): {
    totalCalls: number;
    totalTokens: number;
    totalCost: number;
  } {
    const stats = this.getAllStats();
    let totalCalls = 0;
    let totalTokens = 0;
    let totalCost = 0;

    for (const modelStats of Object.values(stats)) {
      totalCalls += modelStats.totalCalls;
      totalTokens += modelStats.totalTokens;
      totalCost += modelStats.estimatedCost;
    }

    return { totalCalls, totalTokens, totalCost };
  }
}

/**
 * Instance singleton du service de tracking
 */
export const openaiTracker = new OpenAITrackerService();

